
Reduction of online learning to MTS with uniform metric

A gradient descent based strategy (three views: descent form, proximal form, and regularization form)
Beyond Euclidean spaces: mirror descent
A continuous time mirror descent
Lyapunov function analysis
? Guessing the discrete time bound with second order derivative in the potential

Gradient descent (three forms?)
But look at the L^1 norm
Continuous-time mirror descent [Riemannian derivation]
Lyapunov function

[2nd order?]


Next post:

MTS on a weighted star
- Recall the definition of MTS
- State the mirror map and the algorithm
- Do the Bregman analysis that motivatives which mirror map to use
- Do the Lipschitz analysis for OPT
- Discuss the Lagrangian multipliers / movement analysis
- A\delta = b?

k-server on a weighted star
- Discuss a different way of implementing the shift
- Analyze k-server
- Discuss the marking algorithm
- Ask about online rounding

